{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSE257-final-project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VnZIU0uGd5V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "70563b34-277e-4913-ffef-2c7ad7706ee3"
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting absl-py==0.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/07/f69dd3367368ad69f174bfe426a973651412ec11d48ec05c000f19fe0561/absl_py-0.10.0-py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 5.3MB/s \n",
            "\u001b[?25hCollecting aiohttp==3.6.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/71/6000eacb8923d9fd07aa8784a8fab4f022ae697f3c2456d7dca75c743dd6/aiohttp-3.6.2-cp37-cp37m-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 19.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.6.3)\n",
            "Collecting async-timeout==3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting attrs==20.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/df/479736ae1ef59842f512548bacefad1abed705e400212acba43f9b0fa556/attrs-20.2.0-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.5MB/s \n",
            "\u001b[?25hCollecting cachetools==4.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/5c/f3aa86b6d5482f3051b433c7616668a9b96fbe49a622210e2c9781938a5c/cachetools-4.1.1-py3-none-any.whl\n",
            "Collecting certifi==2020.6.20\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/c4/6c4fe722df5343c33226f0b4e0bb042e4dc13483228b4718baf286f86d87/certifi-2020.6.20-py2.py3-none-any.whl (156kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 28.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (3.0.4)\n",
            "Collecting chex==0.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/f8/da/a58571dbb014f0ba1a10b97aac6ceb67d2588069e1e9cbbe67964d19f7f0/chex-0.0.2-py3-none-any.whl\n",
            "Collecting cloudpickle==1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (4.4.2)\n",
            "Collecting dill==0.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/96/518a8ea959a734b70d2e95fef98bcbfdc7adad1c1e5f5dd9148c835205a5/dill-0.3.2.zip (177kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 23.1MB/s \n",
            "\u001b[?25hCollecting dm-env==1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/91/9a/52419cf918d62768a53165d349434cd8b1a0bb71127c3b71d3b019dbffcc/dm_env-1.2-py3-none-any.whl\n",
            "Collecting dm-haiku==0.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/6a/b7b62e33fd9c1f531eca24f87603d3d84baae90fa3f228350689ebb34af9/dm_haiku-0.0.2-py3-none-any.whl (241kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 27.7MB/s \n",
            "\u001b[?25hCollecting dm-tree==0.1.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/d9/6d88e8d32bb454c4ef8f50c62714b0eb20170f4c1d2cd316e0d99755405e/dm_tree-0.1.5-cp37-cp37m-manylinux1_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 24.4MB/s \n",
            "\u001b[?25hCollecting future==0.18.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 27.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (0.3.3)\n",
            "Collecting google-auth==1.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/3f/7fbf002e01c17c35cb68de64ab2cfc069fd6aca5b8fdc44a34490d993279/google_auth-1.22.0-py2.py3-none-any.whl (114kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 39.9MB/s \n",
            "\u001b[?25hCollecting google-auth-oauthlib==0.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (0.2.0)\n",
            "Collecting googleapis-common-protos==1.52.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/74/3956721ea1eb4bcf7502a311fdaa60b85bd751de4e57d1943afe9b334141/googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio==1.32.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (1.32.0)\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 23)) (2.10.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 24)) (2.10)\n",
            "Collecting jax==0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/d9/9bd335976d3b61f705c2e9c35da2c6e030f9cd9ffd3e111feb99d8d169a7/jax-0.2.0.tar.gz (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 37.6MB/s \n",
            "\u001b[?25hCollecting jaxlib==0.1.55\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/c5/d38841eb7034e984dbf826857a3a0fafd54cac038bfe0c79a6d932929e40/jaxlib-0.1.55-cp37-none-manylinux2010_x86_64.whl (31.9MB)\n",
            "\u001b[K     |████████████████████████████████| 31.9MB 260kB/s \n",
            "\u001b[?25hRequirement already satisfied: Keras-Preprocessing==1.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 27)) (1.1.2)\n",
            "Collecting Markdown==3.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/63/eaec2bd025ab48c754b55e8819af0f6a69e2b1e187611dd40cbbe101ee7f/Markdown-3.2.2-py3-none-any.whl (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 3.2MB/s \n",
            "\u001b[?25hCollecting multidict==4.7.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/b8/a9fe777dab4c6aa067b516a34fe995213707e490ea1e72f823949a830a6a/multidict-4.7.6-cp37-cp37m-manylinux1_x86_64.whl (149kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 54.4MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/c6/58e517e8b1fb192725cfa23c01c2e60e4e6699314ee9684a1c5f5c9b27e1/numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauthlib==3.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 31)) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 32)) (3.3.0)\n",
            "Requirement already satisfied: promise==2.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 33)) (2.3)\n",
            "Collecting protobuf==3.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/dc/5ba56eab7440c62c5f808b4267e2a1d6c136e90293b43fefb1b493c6d704/protobuf-3.13.0-cp37-cp37m-manylinux1_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 49.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 35)) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 36)) (0.2.8)\n",
            "Collecting requests==2.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib==1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 38)) (1.3.0)\n",
            "Collecting rlax==0.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/0b/e69f7206c8098fc2a26e3cf86c56dcd4d72621c741f83b543efb37e0ed39/rlax-0.0.2-py3-none-any.whl (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.1MB/s \n",
            "\u001b[?25hCollecting rsa==4.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/df/c3587a667d6b308fadc90b99e8bc8774788d033efcc70f4ecaae7fad144b/rsa-4.6-py3-none-any.whl (47kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hCollecting scipy==1.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/f9/f7a7e5009711579c72da2725174825e5056741bf4001815d097eef1b2e17/scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (25.9MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9MB 148kB/s \n",
            "\u001b[?25hRequirement already satisfied: six==1.15.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 42)) (1.15.0)\n",
            "Collecting tensorboard==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/1b/6a420d7e6ba431cf3d51b2a5bfa06a958c4141e3189385963dc7f6fbffb6/tensorboard-2.3.0-py3-none-any.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 29.6MB/s \n",
            "\u001b[?25hCollecting tensorboard-plugin-wit==1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/85/5c5ac0a8c5efdfab916e9c6bc18963f6a6996a8a1e19ec4ad8c9ac9c623c/tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779kB)\n",
            "\u001b[K     |████████████████████████████████| 788kB 45.3MB/s \n",
            "\u001b[?25hCollecting tensorflow==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/18/374af421dfbe74379a458e58ab40cf46b35c3206ce8e183e28c1c627494d/tensorflow-2.3.1-cp37-cp37m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 22kB/s \n",
            "\u001b[?25hCollecting tensorflow-datasets==3.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/c9/d97bdf931edbae9aebc767633d088bd674136d5fe7587ef693b7cb6a1883/tensorflow_datasets-3.2.1-py3-none-any.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 51.6MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/ed/5853ec0ae380cba4588eab1524e18ece1583b65f7ae0e97321f5ff9dfd60/tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 55.7MB/s \n",
            "\u001b[?25hCollecting tensorflow-metadata==0.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/c4/1ff6a8afaac19250780a82bc05907586f6c23f45a5983df8921040e2b04c/tensorflow_metadata-0.24.0-py3-none-any.whl (44kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.8MB/s \n",
            "\u001b[?25hCollecting tensorflow-probability==0.11.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/99/07d4220b021a5d6f6b3de8872f2a634389ad224f8508258452e57aaaf328/tensorflow_probability-0.11.1-py2.py3-none-any.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 52.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 50)) (1.1.0)\n",
            "Requirement already satisfied: toolz==0.11.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 51)) (0.11.1)\n",
            "Collecting tqdm==4.50.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/0e/ea53a3d6f1eb2cc31162c9ae89555cc26a3986e5559781f0b0df75aea5cf/tqdm-4.50.0-py2.py3-none-any.whl (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.2MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 56.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse==1.6.3->-r requirements.txt (line 3)) (0.36.2)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth==1.22.0->-r requirements.txt (line 18)) (56.1.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from Markdown==3.2.2->-r requirements.txt (line 28)) (4.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->-r requirements.txt (line 37)) (1.24.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0->-r requirements.txt (line 43)) (2.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1->-r requirements.txt (line 45)) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.6.2->-r requirements.txt (line 2)) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->Markdown==3.2.2->-r requirements.txt (line 28)) (3.4.1)\n",
            "Building wheels for collected packages: dill, future, jax\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.2-cp37-none-any.whl size=78912 sha256=782f233f66896f5aa47a8fde0892c9fc8edcb4c9311909cf4f38b0f5ad382552\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/4b/a2/34ccdcc2f158742cfe9650675560dea85f78c3f4628f7daad0\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=02b14067dc93f2b159d9ac2062b757d2a5b89931dc105f26008593bbe8c795aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax: filename=jax-0.2.0-cp37-none-any.whl size=522277 sha256=757345cf1c8ee74872c59fbfe0fd16c57561b55330b07e0038dc179788149042\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/f1/91/e9c21aca3142a6d2e5e760162fd65a1430438b7630a0b75591\n",
            "Successfully built dill future jax\n",
            "\u001b[31mERROR: pymc3 3.11.2 has requirement cachetools>=4.2.1, but you'll have cachetools 4.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: multiprocess 0.70.11.1 has requirement dill>=0.3.3, but you'll have dill 0.3.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.24.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: absl-py, multidict, async-timeout, yarl, attrs, aiohttp, cachetools, certifi, numpy, jax, scipy, jaxlib, chex, cloudpickle, dill, dm-tree, dm-env, dm-haiku, future, rsa, google-auth, google-auth-oauthlib, protobuf, googleapis-common-protos, Markdown, requests, rlax, tensorboard-plugin-wit, tensorboard, tensorflow-estimator, tensorflow, tqdm, tensorflow-metadata, tensorflow-datasets, tensorflow-probability\n",
            "  Found existing installation: absl-py 0.12.0\n",
            "    Uninstalling absl-py-0.12.0:\n",
            "      Successfully uninstalled absl-py-0.12.0\n",
            "  Found existing installation: attrs 21.2.0\n",
            "    Uninstalling attrs-21.2.0:\n",
            "      Successfully uninstalled attrs-21.2.0\n",
            "  Found existing installation: cachetools 4.2.2\n",
            "    Uninstalling cachetools-4.2.2:\n",
            "      Successfully uninstalled cachetools-4.2.2\n",
            "  Found existing installation: certifi 2020.12.5\n",
            "    Uninstalling certifi-2020.12.5:\n",
            "      Successfully uninstalled certifi-2020.12.5\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: jax 0.2.13\n",
            "    Uninstalling jax-0.2.13:\n",
            "      Successfully uninstalled jax-0.2.13\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Found existing installation: jaxlib 0.1.66+cuda110\n",
            "    Uninstalling jaxlib-0.1.66+cuda110:\n",
            "      Successfully uninstalled jaxlib-0.1.66+cuda110\n",
            "  Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Found existing installation: dill 0.3.3\n",
            "    Uninstalling dill-0.3.3:\n",
            "      Successfully uninstalled dill-0.3.3\n",
            "  Found existing installation: dm-tree 0.1.6\n",
            "    Uninstalling dm-tree-0.1.6:\n",
            "      Successfully uninstalled dm-tree-0.1.6\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: rsa 4.7.2\n",
            "    Uninstalling rsa-4.7.2:\n",
            "      Successfully uninstalled rsa-4.7.2\n",
            "  Found existing installation: google-auth 1.30.0\n",
            "    Uninstalling google-auth-1.30.0:\n",
            "      Successfully uninstalled google-auth-1.30.0\n",
            "  Found existing installation: google-auth-oauthlib 0.4.4\n",
            "    Uninstalling google-auth-oauthlib-0.4.4:\n",
            "      Successfully uninstalled google-auth-oauthlib-0.4.4\n",
            "  Found existing installation: protobuf 3.12.4\n",
            "    Uninstalling protobuf-3.12.4:\n",
            "      Successfully uninstalled protobuf-3.12.4\n",
            "  Found existing installation: googleapis-common-protos 1.53.0\n",
            "    Uninstalling googleapis-common-protos-1.53.0:\n",
            "      Successfully uninstalled googleapis-common-protos-1.53.0\n",
            "  Found existing installation: Markdown 3.3.4\n",
            "    Uninstalling Markdown-3.3.4:\n",
            "      Successfully uninstalled Markdown-3.3.4\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: tensorboard-plugin-wit 1.8.0\n",
            "    Uninstalling tensorboard-plugin-wit-1.8.0:\n",
            "      Successfully uninstalled tensorboard-plugin-wit-1.8.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: tensorflow-metadata 0.30.0\n",
            "    Uninstalling tensorflow-metadata-0.30.0:\n",
            "      Successfully uninstalled tensorflow-metadata-0.30.0\n",
            "  Found existing installation: tensorflow-datasets 4.0.1\n",
            "    Uninstalling tensorflow-datasets-4.0.1:\n",
            "      Successfully uninstalled tensorflow-datasets-4.0.1\n",
            "  Found existing installation: tensorflow-probability 0.12.1\n",
            "    Uninstalling tensorflow-probability-0.12.1:\n",
            "      Successfully uninstalled tensorflow-probability-0.12.1\n",
            "Successfully installed Markdown-3.2.2 absl-py-0.10.0 aiohttp-3.6.2 async-timeout-3.0.1 attrs-20.2.0 cachetools-4.1.1 certifi-2020.6.20 chex-0.0.2 cloudpickle-1.6.0 dill-0.3.2 dm-env-1.2 dm-haiku-0.0.2 dm-tree-0.1.5 future-0.18.2 google-auth-1.22.0 google-auth-oauthlib-0.4.1 googleapis-common-protos-1.52.0 jax-0.2.0 jaxlib-0.1.55 multidict-4.7.6 numpy-1.18.5 protobuf-3.13.0 requests-2.24.0 rlax-0.0.2 rsa-4.6 scipy-1.5.2 tensorboard-2.3.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.1 tensorflow-datasets-3.2.1 tensorflow-estimator-2.3.0 tensorflow-metadata-0.24.0 tensorflow-probability-0.11.1 tqdm-4.50.0 yarl-1.6.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "1Go5i4p5PpDA",
        "outputId": "0ebde4f5-53f7-4856-e7cf-178698eede36"
      },
      "source": [
        "!pip3 install --upgrade pip setuptools wheel"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/82/04e9aaf603fdbaecb4323b9e723f13c92c245f6ab2902195c53987848c78/pip-21.1.2-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 15.5MB/s \n",
            "\u001b[?25hCollecting setuptools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/78/56aa1b5f4d8ac548755ae767d84f0be54fdd9d404197a3d9e4659d272348/setuptools-57.0.0-py3-none-any.whl (821kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 46.2MB/s \n",
            "\u001b[?25hRequirement already up-to-date: wheel in /usr/local/lib/python3.7/dist-packages (0.36.2)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pip, setuptools\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "  Found existing installation: setuptools 56.1.0\n",
            "    Uninstalling setuptools-56.1.0:\n",
            "      Successfully uninstalled setuptools-56.1.0\n",
            "Successfully installed pip-21.1.2 setuptools-57.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Cqub6fLJOZA",
        "outputId": "cd7840dc-62e8-44ef-c3c0-aebd406fd187"
      },
      "source": [
        "import requests\n",
        "import os\n",
        "if 'TPU_DRIVER_MODE' not in globals():\n",
        "  url = 'http://' + os.environ['COLAB_TPU_ADDR'].split(':')[0] + ':8475/requestversion/tpu_driver0.1-dev20191206'\n",
        "  resp = requests.post(url)\n",
        "  TPU_DRIVER_MODE = 1\n",
        "\n",
        "# The following is required to use TPU Driver as JAX's backend.\n",
        "from jax.config import config\n",
        "config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
        "config.FLAGS.jax_backend_target = \"grpc://\" + os.environ['COLAB_TPU_ADDR']\n",
        "print(config.FLAGS.jax_backend_target)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "grpc://10.83.236.114:8470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zh01u9nJS0vb",
        "outputId": "b5b94ed8-f0ee-4f7a-9be1-927d494aef6d"
      },
      "source": [
        "from jax.lib import xla_bridge\n",
        "xla_bridge.get_backend().devices()\n",
        "xla_bridge.xla_client.get_local_backend().platform"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'gpu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "E197YeTcRlQ7",
        "outputId": "55e73086-0d81-49d7-9750-24a852274486"
      },
      "source": [
        "!pip3 install --upgrade jax jaxlib==0.1.65+cuda111 -f https://storage.googleapis.com/jax-releases/jax_releases.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_releases.html\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.7/dist-packages (0.2.13)\n",
            "Collecting jaxlib==0.1.65+cuda111\n",
            "  Downloading https://storage.googleapis.com/jax-releases/cuda111/jaxlib-0.1.65%2Bcuda111-cp37-none-manylinux2010_x86_64.whl (189.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 189.4 MB 11 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.65+cuda111) (1.18.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.65+cuda111) (0.10.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.65+cuda111) (1.5.2)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.65+cuda111) (1.12)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jaxlib==0.1.65+cuda111) (1.15.0)\n",
            "Installing collected packages: jaxlib\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.1.57+cuda111\n",
            "    Uninstalling jaxlib-0.1.57+cuda111:\n",
            "      Successfully uninstalled jaxlib-0.1.57+cuda111\n",
            "Successfully installed jaxlib-0.1.65+cuda111\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "jaxlib"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhOt68mHENU8",
        "outputId": "7777d705-ad5e-46ca-8c75-cde67a28792a"
      },
      "source": [
        "!unzip gated_linear_networks.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  gated_linear_networks.zip\n",
            "   creating: gated_linear_networks/\n",
            "  inflating: __MACOSX/._gated_linear_networks  \n",
            "  inflating: gated_linear_networks/.DS_Store  \n",
            "  inflating: __MACOSX/gated_linear_networks/._.DS_Store  \n",
            "  inflating: gated_linear_networks/requirements.txt  \n",
            "  inflating: __MACOSX/gated_linear_networks/._requirements.txt  \n",
            "  inflating: gated_linear_networks/my_example.py  \n",
            "   creating: gated_linear_networks/colabs/\n",
            "  inflating: __MACOSX/gated_linear_networks/._colabs  \n",
            "   creating: gated_linear_networks/__pycache__/\n",
            "  inflating: __MACOSX/gated_linear_networks/.___pycache__  \n",
            "  inflating: gated_linear_networks/run.sh  \n",
            "  inflating: __MACOSX/gated_linear_networks/._run.sh  \n",
            "  inflating: gated_linear_networks/README.md  \n",
            "  inflating: __MACOSX/gated_linear_networks/._README.md  \n",
            "   creating: gated_linear_networks/examples/\n",
            "  inflating: __MACOSX/gated_linear_networks/._examples  \n",
            "  inflating: gated_linear_networks/bernoulli_test.py  \n",
            "  inflating: __MACOSX/gated_linear_networks/._bernoulli_test.py  \n",
            "  inflating: gated_linear_networks/bernoulli.py  \n",
            "  inflating: __MACOSX/gated_linear_networks/._bernoulli.py  \n",
            "  inflating: gated_linear_networks/gaussian_test.py  \n",
            "  inflating: __MACOSX/gated_linear_networks/._gaussian_test.py  \n",
            "  inflating: gated_linear_networks/base.py  \n",
            "  inflating: __MACOSX/gated_linear_networks/._base.py  \n",
            "  inflating: gated_linear_networks/gaussian.py  \n",
            "  inflating: __MACOSX/gated_linear_networks/._gaussian.py  \n",
            "  inflating: gated_linear_networks/colabs/README.md  \n",
            "  inflating: __MACOSX/gated_linear_networks/colabs/._README.md  \n",
            "  inflating: gated_linear_networks/colabs/dendritic_gated_network.ipynb  \n",
            "  inflating: __MACOSX/gated_linear_networks/colabs/._dendritic_gated_network.ipynb  \n",
            "  inflating: gated_linear_networks/__pycache__/bernoulli.cpython-37.pyc  \n",
            "  inflating: gated_linear_networks/__pycache__/base.cpython-37.pyc  \n",
            "  inflating: gated_linear_networks/examples/utils_test.py  \n",
            "  inflating: __MACOSX/gated_linear_networks/examples/._utils_test.py  \n",
            "  inflating: gated_linear_networks/examples/bernoulli_mnist.py  \n",
            "  inflating: __MACOSX/gated_linear_networks/examples/._bernoulli_mnist.py  \n",
            "   creating: gated_linear_networks/examples/__pycache__/\n",
            "  inflating: __MACOSX/gated_linear_networks/examples/.___pycache__  \n",
            "  inflating: gated_linear_networks/examples/utils.py  \n",
            "  inflating: __MACOSX/gated_linear_networks/examples/._utils.py  \n",
            "  inflating: gated_linear_networks/examples/__pycache__/utils.cpython-37.pyc  \n",
            "  inflating: gated_linear_networks/examples/__pycache__/bernoulli_mnist.cpython-37.pyc  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOZlcYe8svcP",
        "outputId": "971207d6-9d64-44e4-896f-5a4165ad5c43"
      },
      "source": [
        "!pip3 install --upgrade tf_slim"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 24.0 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40 kB 20.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 352 kB 9.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQuTkHncVWkV",
        "outputId": "b730e3bc-320d-4756-c701-f6a2ae397dda"
      },
      "source": [
        "!pip3 install chex\n",
        "!pip3 install dm-haiku\n",
        "!pip3 install rlax"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting chex\n",
            "  Downloading chex-0.0.7-py3-none-any.whl (52 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▎                         | 10 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 20 kB 32.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 30 kB 35.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 40 kB 23.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 51 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 52 kB 877 kB/s \n",
            "\u001b[?25hRequirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from chex) (0.1.66+cuda110)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from chex) (0.2.13)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from chex) (1.19.5)\n",
            "Requirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex) (0.1.6)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex) (0.11.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.9.0->chex) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->chex) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->chex) (1.12)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->chex) (1.4.1)\n",
            "Installing collected packages: chex\n",
            "Successfully installed chex-0.0.7\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting dm-haiku\n",
            "  Downloading dm_haiku-0.0.4-py3-none-any.whl (284 kB)\n",
            "\u001b[K     |████████████████████████████████| 284 kB 13.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (1.19.5)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (0.8.9)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.7.1->dm-haiku) (1.15.0)\n",
            "Installing collected packages: dm-haiku\n",
            "Successfully installed dm-haiku-0.0.4\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting rlax\n",
            "  Downloading rlax-0.0.3-py3-none-any.whl (110 kB)\n",
            "\u001b[K     |████████████████████████████████| 110 kB 14.1 MB/s \n",
            "\u001b[?25hCollecting dm-env>=1.2\n",
            "  Downloading dm_env-1.4-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chex>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from rlax) (0.0.7)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from rlax) (0.1.66+cuda110)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from rlax) (0.2.13)\n",
            "Requirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from rlax) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from rlax) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.9.0->rlax) (1.15.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.3->rlax) (0.11.1)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.3->rlax) (0.1.6)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->rlax) (3.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->rlax) (1.4.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->rlax) (1.12)\n",
            "Installing collected packages: dm-env, rlax\n",
            "Successfully installed dm-env-1.4 rlax-0.0.3\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp3_mXnpXS5y"
      },
      "source": [
        "\"\"\"Haiku modules for feature processing.\"\"\"\n",
        "\n",
        "import copy\n",
        "from typing import Tuple\n",
        "\n",
        "import chex\n",
        "import haiku as hk\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "from scipy.ndimage import interpolation\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "Array = chex.Array\n",
        "\n",
        "\n",
        "def _moments(image):\n",
        "  \"\"\"Compute the first and second moments of a given image.\"\"\"\n",
        "  c0, c1 = np.mgrid[:image.shape[0], :image.shape[1]]\n",
        "  total_image = np.sum(image)\n",
        "  m0 = np.sum(c0 * image) / total_image\n",
        "  m1 = np.sum(c1 * image) / total_image\n",
        "  m00 = np.sum((c0 - m0)**2 * image) / total_image\n",
        "  m11 = np.sum((c1 - m1)**2 * image) / total_image\n",
        "  m01 = np.sum((c0 - m0) * (c1 - m1) * image) / total_image\n",
        "  mu_vector = np.array([m0, m1])\n",
        "  covariance_matrix = np.array([[m00, m01], [m01, m11]])\n",
        "  return mu_vector, covariance_matrix\n",
        "\n",
        "\n",
        "def _deskew(image):\n",
        "  \"\"\"Image deskew.\"\"\"\n",
        "  c, v = _moments(image)\n",
        "  alpha = v[0, 1] / v[0, 0]\n",
        "  affine = np.array([[1, 0], [alpha, 1]])\n",
        "  ocenter = np.array(image.shape) / 2.0\n",
        "  offset = c - np.dot(affine, ocenter)\n",
        "  return interpolation.affine_transform(image, affine, offset=offset)\n",
        "\n",
        "\n",
        "def _deskew_dataset(dataset):\n",
        "  \"\"\"Dataset deskew.\"\"\"\n",
        "  deskewed = copy.deepcopy(dataset)\n",
        "  for k, before in dataset.items():\n",
        "    images = before[\"image\"]\n",
        "    num_images = images.shape[0]\n",
        "    after = np.stack([_deskew(i) for i in np.squeeze(images, axis=-1)], axis=0)\n",
        "    deskewed[k][\"image\"] = np.reshape(after, (num_images, -1))\n",
        "  return deskewed\n",
        "\n",
        "\n",
        "def load_deskewed_mnist(*a, **k):\n",
        "  \"\"\"Returns deskewed MNIST numpy dataset.\"\"\"\n",
        "  mnist_data, info = tfds.load(*a, **k)\n",
        "  mnist_data = tfds.as_numpy(mnist_data)\n",
        "  deskewed_data = _deskew_dataset(mnist_data)\n",
        "  return deskewed_data, info\n",
        "\n",
        "\n",
        "class MeanStdEstimator(hk.Module):\n",
        "  \"\"\"Online mean and standard deviation estimator using Welford's algorithm.\"\"\"\n",
        "\n",
        "  def __call__(self, sample: jnp.DeviceArray) -> Tuple[Array, Array]:\n",
        "    if len(sample.shape) > 1:\n",
        "      raise ValueError(\"sample must be a rank 0 or 1 DeviceArray.\")\n",
        "\n",
        "    count = hk.get_state(\"count\", shape=(), dtype=jnp.int32, init=jnp.zeros)\n",
        "    mean = hk.get_state(\n",
        "        \"mean\", shape=sample.shape, dtype=jnp.float32, init=jnp.zeros)\n",
        "    m2 = hk.get_state(\n",
        "        \"m2\", shape=sample.shape, dtype=jnp.float32, init=jnp.zeros)\n",
        "\n",
        "    count += 1\n",
        "    delta = sample - mean\n",
        "    mean += delta / count\n",
        "    delta_2 = sample - mean\n",
        "    m2 += delta * delta_2\n",
        "\n",
        "    hk.set_state(\"count\", count)\n",
        "    hk.set_state(\"mean\", mean)\n",
        "    hk.set_state(\"m2\", m2)\n",
        "\n",
        "    stddev = jnp.sqrt(m2 / count)\n",
        "    return mean, stddev"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sggrdGkzW0ab"
      },
      "source": [
        "\"\"\"Bernoulli Gated Linear Network.\"\"\"\n",
        "\n",
        "from typing import List, Text, Tuple\n",
        "\n",
        "import chex\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import rlax\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "from gated_linear_networks import base\n",
        "\n",
        "#tfp = tfp.experimental.substrates.jax\n",
        "#tfd = tfp.distributions\n",
        "\n",
        "Array = chex.Array\n",
        "\n",
        "GLN_EPS = 0.01\n",
        "MAX_WEIGHT = 200.\n",
        "\n",
        "\n",
        "class GatedLinearNetwork(base.GatedLinearNetwork):\n",
        "  \"\"\"Bernoulli Gated Linear Network.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               output_sizes: List[int],\n",
        "               context_dim: int,\n",
        "               name: Text = \"bernoulli_gln\"):\n",
        "    \"\"\"Initialize a Bernoulli GLN.\"\"\"\n",
        "    super(GatedLinearNetwork, self).__init__(\n",
        "        output_sizes,\n",
        "        context_dim,\n",
        "        inference_fn=GatedLinearNetwork._inference_fn,\n",
        "        update_fn=GatedLinearNetwork._update_fn,\n",
        "        init=jnp.zeros,\n",
        "        dtype=jnp.float32,\n",
        "        name=name)\n",
        "\n",
        "  def _add_bias(self, inputs):\n",
        "    return jnp.append(inputs, rlax.sigmoid(1.))\n",
        "\n",
        "  @staticmethod\n",
        "  def _inference_fn(\n",
        "      inputs: Array,           # [input_size]\n",
        "      side_info: Array,        # [side_info_size]\n",
        "      weights: Array,          # [2**context_dim, input_size]\n",
        "      hyperplanes: Array,      # [context_dim, side_info_size]\n",
        "      hyperplane_bias: Array,  # [context_dim]\n",
        "  ) -> Array:\n",
        "    \"\"\"Inference step for a single Beurnolli neuron.\"\"\"\n",
        "\n",
        "    weight_index = GatedLinearNetwork._compute_context(side_info, hyperplanes,\n",
        "                                                       hyperplane_bias)\n",
        "    used_weights = weights[weight_index]\n",
        "    inputs = rlax.logit(jnp.clip(inputs, GLN_EPS, 1. - GLN_EPS))\n",
        "    prediction = rlax.sigmoid(jnp.dot(used_weights, inputs))\n",
        "\n",
        "    return prediction\n",
        "\n",
        "  @staticmethod\n",
        "  def _update_fn(\n",
        "      inputs: Array,           # [input_size]\n",
        "      side_info: Array,        # [side_info_size]\n",
        "      weights: Array,          # [2**context_dim, num_features]\n",
        "      hyperplanes: Array,      # [context_dim, side_info_size]\n",
        "      hyperplane_bias: Array,  # [context_dim]\n",
        "      target: Array,           # []\n",
        "      learning_rate: float,\n",
        "  ) -> Tuple[Array, Array, Array]:\n",
        "    \"\"\"Update step for a single Bernoulli neuron.\"\"\"\n",
        "\n",
        "    def log_loss_fn(inputs, side_info, weights, hyperplanes, hyperplane_bias,\n",
        "                    target):\n",
        "      \"\"\"Log loss for a single Bernoulli neuron.\"\"\"\n",
        "      prediction = GatedLinearNetwork._inference_fn(inputs, side_info, weights,\n",
        "                                                    hyperplanes,\n",
        "                                                    hyperplane_bias)\n",
        "      prediction = jnp.clip(prediction, GLN_EPS, 1. - GLN_EPS)\n",
        "      return rlax.log_loss(prediction, target), prediction\n",
        "\n",
        "    grad_log_loss = jax.value_and_grad(log_loss_fn, argnums=2, has_aux=True)\n",
        "    ((log_loss, prediction),\n",
        "     dloss_dweights) = grad_log_loss(inputs, side_info, weights, hyperplanes,\n",
        "                                     hyperplane_bias, target)\n",
        "\n",
        "    delta_weights = learning_rate * dloss_dweights\n",
        "    new_weights = jnp.clip(weights - delta_weights, -MAX_WEIGHT, MAX_WEIGHT)\n",
        "    return new_weights, prediction, log_loss\n",
        "\n",
        "\n",
        "class LastNeuronAggregator(base.LastNeuronAggregator):\n",
        "  \"\"\"Bernoulli last neuron aggregator, implemented by the super class.\"\"\"\n",
        "  pass\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vo0QEy5Rxty",
        "outputId": "f7ae5464-76b8-427b-9061-b9cb8b5ea612"
      },
      "source": [
        "#from absl import app\n",
        "#from absl import flags\n",
        "\n",
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import rlax\n",
        "\n",
        "#from gated_linear_networks import bernoulli\n",
        "#from gated_linear_networks.examples import utils\n",
        "#import bernoulli\n",
        "#from examples import utils\n",
        "\n",
        "MAX_TRAIN_STEPS = 50\n",
        "\n",
        "# Small example network, achieves ~95% test set accuracy =======================\n",
        "# Network parameters.\n",
        "NUM_LAYERS = 2\n",
        "\n",
        "NEURONS_PER_LAYER = 70\n",
        "\n",
        "CONTEXT_DIM = 1\n",
        "\n",
        "\n",
        "# Learning rate schedule.\n",
        "MAX_LR = 0.003\n",
        "\n",
        "LR_CONSTANT = 1.0\n",
        "\n",
        "LR_DECAY = 0.1\n",
        "\n",
        "\n",
        "# Logging parameters.\n",
        "#EVALUATE_EVERY = 1000\n",
        "EVALUATE_EVERY = 10\n",
        "\n",
        "\n",
        "def main(unused_argv):\n",
        "  # Load MNIST dataset =========================================================\n",
        "  mnist_data, info = load_deskewed_mnist(\n",
        "      name='mnist', batch_size=-1, with_info=True)\n",
        "  num_classes = info.features['label'].num_classes\n",
        "\n",
        "  (train_images, train_labels) = (mnist_data['train']['image'],\n",
        "                                  mnist_data['train']['label'])\n",
        "\n",
        "  (test_images, test_labels) = (mnist_data['test']['image'],\n",
        "                                mnist_data['test']['label'])\n",
        "  print(train_images.shape)\n",
        "  print(train_labels.shape)\n",
        "\n",
        "  # Build a (binary) GLN classifier ============================================\n",
        "  def network_factory():\n",
        "\n",
        "    def gln_factory():\n",
        "      output_sizes = [NEURONS_PER_LAYER] * NUM_LAYERS + [1]\n",
        "      return GatedLinearNetwork(\n",
        "          output_sizes=output_sizes, context_dim=CONTEXT_DIM)\n",
        "\n",
        "    return LastNeuronAggregator(gln_factory)\n",
        "\n",
        "  def extract_features(image):\n",
        "    mean, stddev = MeanStdEstimator()(image)\n",
        "    standardized_img = (image - mean) / (stddev + 1.)\n",
        "    inputs = rlax.sigmoid(standardized_img)\n",
        "    side_info = standardized_img\n",
        "    return inputs, side_info\n",
        "\n",
        "  def inference_fn(image, *args, **kwargs):\n",
        "    inputs, side_info = extract_features(image)\n",
        "    return network_factory().inference(inputs, side_info, *args, **kwargs)\n",
        "\n",
        "  def update_fn(image, *args, **kwargs):\n",
        "    inputs, side_info = extract_features(image)\n",
        "    return network_factory().update(inputs, side_info, *args, **kwargs)\n",
        "\n",
        "  init_, inference_ = hk.without_apply_rng(\n",
        "      hk.transform_with_state(inference_fn))\n",
        "  _, update_ = hk.without_apply_rng(hk.transform_with_state(update_fn))\n",
        "\n",
        "  # Map along class dimension to create a one-vs-all classifier ================\n",
        "  @jax.jit\n",
        "  def init(dummy_image, key):\n",
        "    \"\"\"One-vs-all classifier init fn.\"\"\"\n",
        "    dummy_images = jnp.stack([dummy_image] * num_classes, axis=0)\n",
        "    keys = jax.random.split(key, num_classes)\n",
        "    return jax.vmap(init_, in_axes=(0, 0))(keys, dummy_images)\n",
        "\n",
        "  @jax.jit\n",
        "  def accuracy(params, state, image, label):\n",
        "    \"\"\"One-vs-all classifier inference fn.\"\"\"\n",
        "    fn = jax.vmap(inference_, in_axes=(0, 0, None))\n",
        "    predictions, unused_state = fn(params, state, image)\n",
        "    return (jnp.argmax(predictions) == label).astype(jnp.float32)\n",
        "\n",
        "  @jax.jit\n",
        "  def update(params, state, step, image, label):\n",
        "    \"\"\"One-vs-all classifier update fn.\"\"\"\n",
        "\n",
        "    # Learning rate schedules.\n",
        "    learning_rate = jnp.minimum(\n",
        "        MAX_LR, LR_CONSTANT / (1. + LR_DECAY * step))\n",
        "\n",
        "    # Update weights and report log-loss.\n",
        "    targets = hk.one_hot(jnp.asarray(label), num_classes)\n",
        "\n",
        "    fn = jax.vmap(update_, in_axes=(0, 0, None, 0, None))\n",
        "    out = fn(params, state, image, targets, learning_rate)\n",
        "    (params, unused_predictions, log_loss), state = out\n",
        "    return (jnp.mean(log_loss), params), state\n",
        "\n",
        "  # Train on train split =======================================================\n",
        "  dummy_image = train_images[0]\n",
        "  params, state = init(dummy_image, jax.random.PRNGKey(42))\n",
        "\n",
        "  for step, (image, label) in enumerate(zip(train_images, train_labels), 1):\n",
        "    (unused_loss, params), state = update(\n",
        "        params,\n",
        "        state,\n",
        "        step,\n",
        "        image,\n",
        "        label,\n",
        "    )\n",
        "\n",
        "    # Evaluate on test split ===================================================\n",
        "    if not step % EVALUATE_EVERY:\n",
        "      batch_accuracy = jax.vmap(accuracy, in_axes=(None, None, 0, 0))\n",
        "      accuracies = batch_accuracy(params, state, test_images, test_labels)\n",
        "      total_accuracy = float(jnp.mean(accuracies))\n",
        "\n",
        "      # Report statistics.\n",
        "      print({\n",
        "          'step': step,\n",
        "          'accuracy': float(total_accuracy),\n",
        "      })\n",
        "\n",
        "    if MAX_TRAIN_STEPS is not None and step >= MAX_TRAIN_STEPS:\n",
        "      return\n",
        "\n",
        "\n",
        "\n",
        "main(0)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(60000,)\n",
            "{'step': 10, 'accuracy': 0.15040001273155212}\n",
            "{'step': 20, 'accuracy': 0.2200000137090683}\n",
            "{'step': 30, 'accuracy': 0.21980001032352448}\n",
            "{'step': 40, 'accuracy': 0.5315999984741211}\n",
            "{'step': 50, 'accuracy': 0.5707000494003296}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "Z-CJ7iY4qyRr",
        "outputId": "12a0bbb7-5898-421a-9fa6-8f99753183ea"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "from absl import app\n",
        "from absl import flags\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from hparams import HParams\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from bandits.algorithms.bootstrapped_bnn_sampling import BootstrappedBNNSampling\n",
        "from bandits.core.contextual_bandit import run_contextual_bandit\n",
        "from bandits.data.data_sampler import sample_adult_data\n",
        "from bandits.data.data_sampler import sample_census_data\n",
        "from bandits.data.data_sampler import sample_covertype_data\n",
        "from bandits.data.data_sampler import sample_jester_data\n",
        "from bandits.data.data_sampler import sample_mushroom_data\n",
        "from bandits.data.data_sampler import sample_statlog_data\n",
        "from bandits.data.data_sampler import sample_stock_data\n",
        "from bandits.algorithms.fixed_policy_sampling import FixedPolicySampling\n",
        "from bandits.algorithms.linear_full_posterior_sampling import LinearFullPosteriorSampling\n",
        "from bandits.algorithms.neural_linear_sampling import NeuralLinearPosteriorSampling\n",
        "from bandits.algorithms.parameter_noise_sampling import ParameterNoiseSampling\n",
        "from bandits.algorithms.posterior_bnn_sampling import PosteriorBNNSampling\n",
        "from bandits.data.synthetic_data_sampler import sample_linear_data\n",
        "from bandits.data.synthetic_data_sampler import sample_sparse_linear_data\n",
        "from bandits.data.synthetic_data_sampler import sample_wheel_bandit_data\n",
        "from bandits.algorithms.uniform_sampling import UniformSampling\n",
        "\n",
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import rlax\n",
        "\n",
        "#from gated_linear_networks import bernoulli\n",
        "#from gated_linear_networks.examples import utils\n",
        "#import bernoulli\n",
        "#from examples import utils\n",
        "\n",
        "MAX_TRAIN_STEPS = 2000\n",
        "\n",
        "# Small example network, achieves ~95% test set accuracy =======================\n",
        "# Network parameters.\n",
        "NUM_LAYERS = 2\n",
        "\n",
        "NEURONS_PER_LAYER = 70\n",
        "\n",
        "CONTEXT_DIM = 1\n",
        "\n",
        "\n",
        "# Learning rate schedule.\n",
        "MAX_LR = 0.003\n",
        "\n",
        "LR_CONSTANT = 1.0\n",
        "\n",
        "LR_DECAY = 0.1\n",
        "\n",
        "\n",
        "# Logging parameters.\n",
        "#EVALUATE_EVERY = 1000\n",
        "EVALUATE_EVERY = 1\n",
        "\n",
        "# Set up your file routes to the data files.\n",
        "base_route = os.getcwd()\n",
        "data_route = 'contextual_bandits/datasets'\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "FLAGS.set_default('alsologtostderr', True)\n",
        "flags.DEFINE_string('logdir', '/tmp/bandits/', 'Base directory to save output')\n",
        "flags.DEFINE_string(\n",
        "    'mushroom_data',\n",
        "    os.path.join(base_route, data_route, 'mushroom.data'),\n",
        "    'Directory where Mushroom data is stored.')\n",
        "flags.DEFINE_string(\n",
        "    'financial_data',\n",
        "    os.path.join(base_route, data_route, 'raw_stock_contexts'),\n",
        "    'Directory where Financial data is stored.')\n",
        "flags.DEFINE_string(\n",
        "    'jester_data',\n",
        "    os.path.join(base_route, data_route, 'jester_data_40jokes_19181users.npy'),\n",
        "    'Directory where Jester data is stored.')\n",
        "flags.DEFINE_string(\n",
        "    'statlog_data',\n",
        "    os.path.join(base_route, data_route, 'shuttle.trn'),\n",
        "    'Directory where Statlog data is stored.')\n",
        "flags.DEFINE_string(\n",
        "    'adult_data',\n",
        "    os.path.join(base_route, data_route, 'adult.full'),\n",
        "    'Directory where Adult data is stored.')\n",
        "flags.DEFINE_string(\n",
        "    'covertype_data',\n",
        "    os.path.join(base_route, data_route, 'covtype.data'),\n",
        "    'Directory where Covertype data is stored.')\n",
        "flags.DEFINE_string(\n",
        "    'census_data',\n",
        "    os.path.join(base_route, data_route, 'USCensus1990.data.txt'),\n",
        "    'Directory where Census data is stored.')\n",
        "\n",
        "\n",
        "def sample_data(data_type, num_contexts=None):\n",
        "  \"\"\"Sample data from given 'data_type'.\n",
        "\n",
        "  Args:\n",
        "    data_type: Dataset from which to sample.\n",
        "    num_contexts: Number of contexts to sample.\n",
        "\n",
        "  Returns:\n",
        "    dataset: Sampled matrix with rows: (context, reward_1, ..., reward_num_act).\n",
        "    opt_rewards: Vector of expected optimal reward for each context.\n",
        "    opt_actions: Vector of optimal action for each context.\n",
        "    num_actions: Number of available actions.\n",
        "    context_dim: Dimension of each context.\n",
        "  \"\"\"\n",
        "\n",
        "  if data_type == 'linear':\n",
        "    # Create linear dataset\n",
        "    num_actions = 8\n",
        "    context_dim = 10\n",
        "    noise_stds = [0.01 * (i + 1) for i in range(num_actions)]\n",
        "    dataset, _, opt_linear = sample_linear_data(num_contexts, context_dim,\n",
        "                                                num_actions, sigma=noise_stds)\n",
        "    opt_rewards, opt_actions = opt_linear\n",
        "  elif data_type == 'sparse_linear':\n",
        "    # Create sparse linear dataset\n",
        "    num_actions = 7\n",
        "    context_dim = 10\n",
        "    noise_stds = [0.01 * (i + 1) for i in range(num_actions)]\n",
        "    num_nnz_dims = int(context_dim / 3.0)\n",
        "    dataset, _, opt_sparse_linear = sample_sparse_linear_data(\n",
        "        num_contexts, context_dim, num_actions, num_nnz_dims, sigma=noise_stds)\n",
        "    opt_rewards, opt_actions = opt_sparse_linear\n",
        "  elif data_type == 'mushroom':\n",
        "    # Create mushroom dataset\n",
        "    num_actions = 2\n",
        "    context_dim = 117\n",
        "    file_name = FLAGS.mushroom_data\n",
        "    dataset, opt_mushroom = sample_mushroom_data(file_name, num_contexts)\n",
        "    opt_rewards, opt_actions = opt_mushroom\n",
        "  elif data_type == 'financial':\n",
        "    num_actions = 8\n",
        "    context_dim = 21\n",
        "    num_contexts = min(3713, num_contexts)\n",
        "    noise_stds = [0.01 * (i + 1) for i in range(num_actions)]\n",
        "    file_name = FLAGS.financial_data\n",
        "    dataset, opt_financial = sample_stock_data(file_name, context_dim,\n",
        "                                               num_actions, num_contexts,\n",
        "                                               noise_stds, shuffle_rows=True)\n",
        "    opt_rewards, opt_actions = opt_financial\n",
        "  elif data_type == 'jester':\n",
        "    num_actions = 8\n",
        "    context_dim = 32\n",
        "    num_contexts = min(19181, num_contexts)\n",
        "    file_name = FLAGS.jester_data\n",
        "    dataset, opt_jester = sample_jester_data(file_name, context_dim,\n",
        "                                             num_actions, num_contexts,\n",
        "                                             shuffle_rows=True,\n",
        "                                             shuffle_cols=True)\n",
        "    opt_rewards, opt_actions = opt_jester\n",
        "  elif data_type == 'statlog':\n",
        "    file_name = FLAGS.statlog_data\n",
        "    num_actions = 7\n",
        "    num_contexts = min(43500, num_contexts)\n",
        "    sampled_vals = sample_statlog_data(file_name, num_contexts,\n",
        "                                       shuffle_rows=True)\n",
        "    contexts, rewards, (opt_rewards, opt_actions) = sampled_vals\n",
        "    dataset = np.hstack((contexts, rewards))\n",
        "    context_dim = contexts.shape[1]\n",
        "  elif data_type == 'adult':\n",
        "    file_name = FLAGS.adult_data\n",
        "    num_actions = 14\n",
        "    num_contexts = min(45222, num_contexts)\n",
        "    sampled_vals = sample_adult_data(file_name, num_contexts,\n",
        "                                     shuffle_rows=True)\n",
        "    contexts, rewards, (opt_rewards, opt_actions) = sampled_vals\n",
        "    dataset = np.hstack((contexts, rewards))\n",
        "    context_dim = contexts.shape[1]\n",
        "  elif data_type == 'covertype':\n",
        "    file_name = FLAGS.covertype_data\n",
        "    num_actions = 7\n",
        "    num_contexts = min(150000, num_contexts)\n",
        "    sampled_vals = sample_covertype_data(file_name, num_contexts,\n",
        "                                         shuffle_rows=True)\n",
        "    contexts, rewards, (opt_rewards, opt_actions) = sampled_vals\n",
        "    dataset = np.hstack((contexts, rewards))\n",
        "    context_dim = contexts.shape[1]\n",
        "  elif data_type == 'census':\n",
        "    file_name = FLAGS.census_data\n",
        "    num_actions = 9\n",
        "    num_contexts = min(150000, num_contexts)\n",
        "    sampled_vals = sample_census_data(file_name, num_contexts,\n",
        "                                      shuffle_rows=True)\n",
        "    contexts, rewards, (opt_rewards, opt_actions) = sampled_vals\n",
        "    dataset = np.hstack((contexts, rewards))\n",
        "    context_dim = contexts.shape[1]\n",
        "  elif data_type == 'wheel':\n",
        "    delta = 0.95\n",
        "    num_actions = 5\n",
        "    context_dim = 2\n",
        "    mean_v = [1.0, 1.0, 1.0, 1.0, 1.2]\n",
        "    std_v = [0.05, 0.05, 0.05, 0.05, 0.05]\n",
        "    mu_large = 50\n",
        "    std_large = 0.01\n",
        "    dataset, opt_wheel = sample_wheel_bandit_data(num_contexts, delta,\n",
        "                                                  mean_v, std_v,\n",
        "                                                  mu_large, std_large)\n",
        "    opt_rewards, opt_actions = opt_wheel\n",
        "\n",
        "  return dataset, opt_rewards, opt_actions, num_actions, context_dim\n",
        "\n",
        "\n",
        "def display_results(algos, opt_rewards, opt_actions, h_rewards, t_init, name):\n",
        "  \"\"\"Displays summary statistics of the performance of each algorithm.\"\"\"\n",
        "\n",
        "  print('---------------------------------------------------')\n",
        "  print('---------------------------------------------------')\n",
        "  print('{} bandit completed after {} seconds.'.format(\n",
        "    name, time.time() - t_init))\n",
        "  print('---------------------------------------------------')\n",
        "\n",
        "  performance_pairs = []\n",
        "  for j, a in enumerate(algos):\n",
        "    performance_pairs.append((a.name, np.sum(h_rewards[:, j])))\n",
        "  performance_pairs = sorted(performance_pairs,\n",
        "                             key=lambda elt: elt[1],\n",
        "                             reverse=True)\n",
        "  for i, (name, reward) in enumerate(performance_pairs):\n",
        "    print('{:3}) {:20}| \\t \\t total reward = {:10}.'.format(i, name, reward))\n",
        "\n",
        "  print('---------------------------------------------------')\n",
        "  print('Optimal total reward = {}.'.format(np.sum(opt_rewards)))\n",
        "  print('Frequency of optimal actions (action, frequency):')\n",
        "  print([[elt, list(opt_actions).count(elt)] for elt in set(opt_actions)])\n",
        "  print('---------------------------------------------------')\n",
        "  print('---------------------------------------------------')\n",
        "\n",
        "\n",
        "def main(_):\n",
        "\n",
        "  # Problem parameters\n",
        "  num_contexts = 2000\n",
        "  num_classes = 14\n",
        "  # Data type in {linear, sparse_linear, mushroom, financial, jester,\n",
        "  #                 statlog, adult, covertype, census, wheel}\n",
        "  data_type = 'adult'\n",
        "\n",
        "  # Create dataset\n",
        "  sampled_vals = sample_data(data_type, num_contexts)\n",
        "  dataset, opt_rewards, opt_actions, num_actions, context_dim = sampled_vals\n",
        "  # dataset: (num_contexts, context_dim + num_actions)\n",
        "  # opt_rewards: (num_contexts,)\n",
        "  dataset = dataset[:, :num_contexts]\n",
        "  labels = opt_actions\n",
        "\n",
        "  # Build a (binary) GLN classifier ============================================\n",
        "  def network_factory():\n",
        "\n",
        "    def gln_factory():\n",
        "      output_sizes = [NEURONS_PER_LAYER] * NUM_LAYERS + [1]\n",
        "      return GatedLinearNetwork(\n",
        "          output_sizes=output_sizes, context_dim=CONTEXT_DIM)\n",
        "\n",
        "    return LastNeuronAggregator(gln_factory)\n",
        "\n",
        "  def extract_features(image):\n",
        "    mean, stddev = MeanStdEstimator()(image)\n",
        "    standardized_img = (image - mean) / (stddev + 1.)\n",
        "    inputs = rlax.sigmoid(standardized_img)\n",
        "    side_info = standardized_img\n",
        "    return inputs, side_info\n",
        "\n",
        "  def inference_fn(image, *args, **kwargs):\n",
        "    inputs, side_info = extract_features(image)\n",
        "    return network_factory().inference(inputs, side_info, *args, **kwargs)\n",
        "\n",
        "  def update_fn(image, *args, **kwargs):\n",
        "    inputs, side_info = extract_features(image)\n",
        "    return network_factory().update(inputs, side_info, *args, **kwargs)\n",
        "\n",
        "  init_, inference_ = hk.without_apply_rng(\n",
        "      hk.transform_with_state(inference_fn))\n",
        "  _, update_ = hk.without_apply_rng(hk.transform_with_state(update_fn))\n",
        "\n",
        "  # Map along class dimension to create a one-vs-all classifier ================\n",
        "  @jax.jit\n",
        "  def init(dummy_image, key):\n",
        "    \"\"\"One-vs-all classifier init fn.\"\"\"\n",
        "    dummy_images = jnp.stack([dummy_image] * num_classes, axis=0)\n",
        "    keys = jax.random.split(key, num_classes)\n",
        "    return jax.vmap(init_, in_axes=(0, 0))(keys, dummy_images)\n",
        "\n",
        "  @jax.jit\n",
        "  def accuracy(params, state, image, label):\n",
        "    \"\"\"One-vs-all classifier inference fn.\"\"\"\n",
        "    fn = jax.vmap(inference_, in_axes=(0, 0, None))\n",
        "    predictions, unused_state = fn(params, state, image)\n",
        "    return (jnp.argmax(predictions) == label).astype(jnp.float32)\n",
        "\n",
        "  @jax.jit\n",
        "  def update(params, state, step, image, label):\n",
        "    \"\"\"One-vs-all classifier update fn.\"\"\"\n",
        "\n",
        "    # Learning rate schedules.\n",
        "    learning_rate = jnp.minimum(\n",
        "        MAX_LR, LR_CONSTANT / (1. + LR_DECAY * step))\n",
        "\n",
        "    # Update weights and report log-loss.\n",
        "    targets = hk.one_hot(jnp.asarray(label), num_classes)\n",
        "\n",
        "    fn = jax.vmap(update_, in_axes=(0, 0, None, 0, None))\n",
        "    out = fn(params, state, image, targets, learning_rate)\n",
        "    (params, unused_predictions, log_loss), state = out\n",
        "    return (jnp.mean(log_loss), params), state\n",
        "\n",
        "  # Train on train split =======================================================\n",
        "  #dummy_image = train_images[0]\n",
        "  dummy_image = dataset[0]\n",
        "  params, state = init(dummy_image, jax.random.PRNGKey(42))\n",
        "  total_rewards = 0.\n",
        "\n",
        "  for step, (image, label) in enumerate(zip(dataset, labels), 1):\n",
        "    (unused_loss, params), state = update(\n",
        "        params,\n",
        "        state,\n",
        "        step,\n",
        "        image,\n",
        "        label,\n",
        "    )\n",
        "\n",
        "    # Evaluate on test split ===================================================\n",
        "    if not step % EVALUATE_EVERY:\n",
        "      batch_accuracy = jax.vmap(accuracy, in_axes=(None, None, 0, 0))\n",
        "      #accuracies = batch_accuracy(params, state, test_images, test_labels)\n",
        "      reward = float(jnp.mean(batch_accuracy(params, state, image, label)))\n",
        "      total_rewards += reward\n",
        "      #total_accuracy = float(jnp.mean(accuracies))\n",
        "\n",
        "      # Report statistics.\n",
        "\n",
        "    if MAX_TRAIN_STEPS is not None and step >= MAX_TRAIN_STEPS:\n",
        "      return\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  app.run(main)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "FATAL Flags parsing error: Unknown command line flag 'f'\n",
            "Pass --helpshort or --helpfull to see help on flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMLFjdfuARVm",
        "outputId": "982f8226-2dcc-4d22-8059-158ed5916d2b"
      },
      "source": [
        "!python contextual_bandit_GLN.py"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "tcmalloc: large alloc 1356980224 bytes == 0x556a49aa8000 @  0x7f0a6599e1e7 0x7f0a52fd346e 0x7f0a53023c7b 0x7f0a5302435f 0x7f0a530c6103 0x55699fc1fd54 0x55699fc1fa50 0x55699fc94105 0x55699fc2130a 0x55699fc8f3b5 0x55699fc8e4ae 0x55699fc213ea 0x55699fc8f3b5 0x55699fc2130a 0x55699fc8f3b5 0x55699fc2130a 0x55699fc8f3b5 0x55699fc8e4ae 0x55699fc213ea 0x55699fc9032a 0x55699fc8e7ad 0x55699fc213ea 0x55699fc9032a 0x55699fc8e7ad 0x55699fc21c9f 0x55699fc62d79 0x55699fc5fcc4 0x55699fc20559 0x55699fc944f8 0x55699fc8e4ae 0x55699fc213ea\n",
            "I0525 22:44:24.434667 139682635380608 utils.py:157] NumExpr defaulting to 4 threads.\n",
            "tcmalloc: large alloc 1356980224 bytes == 0x556a9a8c6000 @  0x7f0a6599e1e7 0x7f0a52fd346e 0x7f0a53023c7b 0x7f0a5302435f 0x7f0a530c6103 0x55699fc1fd54 0x55699fc1fa50 0x55699fc94105 0x55699fc8e4ae 0x55699fc213ea 0x55699fc9032a 0x55699fc8e4ae 0x55699fc213ea 0x55699fc9032a 0x55699fc8e7ad 0x55699fc213ea 0x55699fc8f3b5 0x55699fc8e7ad 0x55699fc213ea 0x55699fc9032a 0x55699fc8e4ae 0x55699fc213ea 0x55699fc9032a 0x55699fc8e4ae 0x55699fc213ea 0x55699fc9032a 0x55699fc8e4ae 0x55699fc213ea 0x55699fc9032a 0x55699fc8e4ae 0x55699fc213ea\n",
            "5000\n",
            "3214.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZgAIisbXgtq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f33e9a6-0c3d-41d1-b685-2888a1facc37"
      },
      "source": [
        "#!rm -r __MACOSX/\n",
        "#!rm -r deep_contextual_bandits/\n",
        "!unzip deep_contextual_bandits.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  deep_contextual_bandits.zip\n",
            "   creating: deep_contextual_bandits/\n",
            "  inflating: __MACOSX/._deep_contextual_bandits  \n",
            "   creating: deep_contextual_bandits/contextual_bandits/\n",
            "  inflating: __MACOSX/deep_contextual_bandits/._contextual_bandits  \n",
            "  inflating: deep_contextual_bandits/.DS_Store  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/._.DS_Store  \n",
            "  inflating: deep_contextual_bandits/hparams.py  \n",
            "   creating: deep_contextual_bandits/bandits/\n",
            "  inflating: __MACOSX/deep_contextual_bandits/._bandits  \n",
            "   creating: deep_contextual_bandits/__pycache__/\n",
            "  inflating: __MACOSX/deep_contextual_bandits/.___pycache__  \n",
            "  inflating: deep_contextual_bandits/example_main.py  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/._example_main.py  \n",
            "  inflating: deep_contextual_bandits/README.md  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/._README.md  \n",
            "  inflating: deep_contextual_bandits/contextual_bandits/.DS_Store  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/contextual_bandits/._.DS_Store  \n",
            "   creating: deep_contextual_bandits/contextual_bandits/datasets/\n",
            "  inflating: __MACOSX/deep_contextual_bandits/contextual_bandits/._datasets  \n",
            "   creating: deep_contextual_bandits/bandits/core/\n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/._core  \n",
            "   creating: deep_contextual_bandits/bandits/algorithms/\n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/._algorithms  \n",
            "   creating: deep_contextual_bandits/bandits/data/\n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/._data  \n",
            "  inflating: deep_contextual_bandits/__pycache__/hparams.cpython-37.pyc  \n",
            "  inflating: deep_contextual_bandits/contextual_bandits/datasets/adult.data  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/contextual_bandits/datasets/._adult.data  \n",
            "  inflating: deep_contextual_bandits/contextual_bandits/datasets/.DS_Store  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/contextual_bandits/datasets/._.DS_Store  \n",
            "  inflating: deep_contextual_bandits/contextual_bandits/datasets/USCensus1990.data.txt  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/contextual_bandits/datasets/._USCensus1990.data.txt  \n",
            "  inflating: deep_contextual_bandits/contextual_bandits/datasets/adult.full  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/contextual_bandits/datasets/._adult.full  \n",
            "  inflating: deep_contextual_bandits/bandits/core/contextual_dataset.py  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/core/._contextual_dataset.py  \n",
            "  inflating: deep_contextual_bandits/bandits/core/bandit_algorithm.py  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/core/._bandit_algorithm.py  \n",
            "  inflating: deep_contextual_bandits/bandits/core/bayesian_nn.py  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/core/._bayesian_nn.py  \n",
            "  inflating: deep_contextual_bandits/bandits/core/contextual_bandit.py  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/core/._contextual_bandit.py  \n",
            "  inflating: deep_contextual_bandits/bandits/core/contextual_bandit_GLN.py  \n",
            "  inflating: deep_contextual_bandits/bandits/algorithms/parameter_noise_sampling.py  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/algorithms/._parameter_noise_sampling.py  \n",
            "  inflating: deep_contextual_bandits/bandits/algorithms/fixed_policy_sampling.py  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/algorithms/._fixed_policy_sampling.py  \n",
            "  inflating: deep_contextual_bandits/bandits/algorithms/bootstrapped_bnn_sampling.py  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/algorithms/._bootstrapped_bnn_sampling.py  \n",
            "  inflating: deep_contextual_bandits/bandits/algorithms/posterior_bnn_sampling.py  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/algorithms/._posterior_bnn_sampling.py  \n",
            "  inflating: deep_contextual_bandits/bandits/algorithms/bf_variational_neural_bandit_model.py  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/algorithms/._bf_variational_neural_bandit_model.py  \n",
            "  inflating: deep_contextual_bandits/bandits/algorithms/bb_alpha_divergence_model.py  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/algorithms/._bb_alpha_divergence_model.py  \n",
            "  inflating: deep_contextual_bandits/bandits/algorithms/multitask_gp.py  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/algorithms/._multitask_gp.py  \n",
            "  inflating: deep_contextual_bandits/bandits/algorithms/neural_linear_sampling.py  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/algorithms/._neural_linear_sampling.py  \n",
            "  inflating: deep_contextual_bandits/bandits/algorithms/neural_bandit_model.py  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/algorithms/._neural_bandit_model.py  \n",
            "  inflating: deep_contextual_bandits/bandits/algorithms/linear_full_posterior_sampling.py  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/algorithms/._linear_full_posterior_sampling.py  \n",
            "  inflating: deep_contextual_bandits/bandits/algorithms/uniform_sampling.py  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/algorithms/._uniform_sampling.py  \n",
            "  inflating: deep_contextual_bandits/bandits/algorithms/variational_neural_bandit_model.py  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/algorithms/._variational_neural_bandit_model.py  \n",
            "  inflating: deep_contextual_bandits/bandits/data/synthetic_data_sampler.py  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/data/._synthetic_data_sampler.py  \n",
            "  inflating: deep_contextual_bandits/bandits/data/data_sampler.py  \n",
            "  inflating: __MACOSX/deep_contextual_bandits/bandits/data/._data_sampler.py  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjjPM9NclgsO",
        "outputId": "69ba514a-f14a-4dd6-bc23-96872247fa5d"
      },
      "source": [
        "!python example_main.py"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "tcmalloc: large alloc 1356980224 bytes == 0x55e7dcac8000 @  0x7faca0f5f1e7 0x7fac9e24e46e 0x7fac9e29ec7b 0x7fac9e29f35f 0x7fac9e341103 0x55e733297d54 0x55e733297a50 0x55e73330c105 0x55e73329930a 0x55e7333073b5 0x55e7333064ae 0x55e7332993ea 0x55e7333073b5 0x55e73329930a 0x55e7333073b5 0x55e73329930a 0x55e7333073b5 0x55e7333064ae 0x55e7332993ea 0x55e73330832a 0x55e7333067ad 0x55e7332993ea 0x55e73330832a 0x55e7333067ad 0x55e733299c9f 0x55e7332dad79 0x55e7332d7cc4 0x55e733298559 0x55e73330c4f8 0x55e7333064ae 0x55e7332993ea\n",
            "I0525 07:01:47.218484 140379415971712 utils.py:157] NumExpr defaulting to 4 threads.\n",
            "tcmalloc: large alloc 1356980224 bytes == 0x55e82d8e6000 @  0x7faca0f5f1e7 0x7fac9e24e46e 0x7fac9e29ec7b 0x7fac9e29f35f 0x7fac9e341103 0x55e733297d54 0x55e733297a50 0x55e73330c105 0x55e7333064ae 0x55e7332993ea 0x55e73330832a 0x55e7333064ae 0x55e7332993ea 0x55e73330832a 0x55e7333067ad 0x55e7332993ea 0x55e7333073b5 0x55e7333067ad 0x55e7332993ea 0x55e73330832a 0x55e7333064ae 0x55e7332993ea 0x55e73330832a 0x55e7333064ae 0x55e7332993ea 0x55e73330832a 0x55e7333064ae 0x55e7332993ea 0x55e73330832a 0x55e7333064ae 0x55e7332993ea\n",
            "2021-05-25 07:01:50.419705: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/rmsprop.py:123: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0525 07:01:50.501696 140379415971712 deprecation.py:537] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/rmsprop.py:123: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "Initializing model RMS-bnn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0525 07:01:50.574169 140379415971712 deprecation.py:537] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Initializing model Dropout-bnn.\n",
            "Initializing model BBB-bnn.\n",
            "WARNING:tensorflow:From /content/bandits/algorithms/variational_neural_bandit_model.py:147: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0525 07:01:50.728677 140379415971712 deprecation.py:339] From /content/bandits/algorithms/variational_neural_bandit_model.py:147: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "Initializing model NeuralLinear-bnn.\n",
            "Initializing model NeuralLinear2-bnn.\n",
            "Initializing model BootRMS-0-bnn.\n",
            "Initializing model BootRMS-1-bnn.\n",
            "Initializing model BootRMS-2-bnn.\n",
            "Initializing model ParamNoise-bnn.\n",
            "Initializing model BBAlphaDiv-bnn.\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.5733333333333334.\n",
            "Update eps=0.099 | kl=0.31762734055519104 | std=0.04950495049504951 | delta=0.09309042306601195 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.45666666666666667.\n",
            "Update eps=0.09801 | kl=0.4157509207725525 | std=0.04901480247034604 | delta=0.09211528890780567 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "/content/bandits/algorithms/linear_full_posterior_sampling.py:99: RuntimeWarning: covariance is not positive-semidefinite.\n",
            "  for i in range(self.hparams.num_actions)\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.5466666666666666.\n",
            "Update eps=0.0970299 | kl=0.3506534993648529 | std=0.04852950739638222 | delta=0.09115084185571282 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Exception when sampling from LinFullPost.\n",
            "Exception when sampling from LinFullPost.\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.5433333333333333.\n",
            "Update eps=0.096059601 | kl=0.291772723197937 | std=0.04804901722414081 | delta=0.09019695464951728 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.5266666666666666.\n",
            "Update eps=0.09509900499 | kl=0.39340880513191223 | std=0.047573284380337436 | delta=0.089253501764772 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.5133333333333333.\n",
            "Update eps=0.0941480149401 | kl=0.3027797043323517 | std=0.04710226176271033 | delta=0.08832035938430659 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6.\n",
            "Update eps=0.093206534790699 | kl=0.35619810223579407 | std=0.04663590273535676 | delta=0.0873974053703076 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.5533333333333333.\n",
            "Update eps=0.09227446944279201 | kl=0.26298391819000244 | std=0.046174161124115605 | delta=0.08648451923695796 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Exception when sampling from LinFullPost.\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.47.\n",
            "Update eps=0.09135172474836409 | kl=0.405124306678772 | std=0.04571699121199565 | delta=0.08558158212362164 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.49333333333333335.\n",
            "Update eps=0.09043820750088044 | kl=0.2911888062953949 | std=0.04526434773464916 | delta=0.08468847676856092 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6066666666666667.\n",
            "Update eps=0.08953382542587164 | kl=0.27430421113967896 | std=0.04481618587589026 | delta=0.08380508748317327 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.5933333333333334.\n",
            "Update eps=0.08863848717161292 | kl=0.33308467268943787 | std=0.04437246126325768 | delta=0.08293130012673564 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Exception when sampling from LinFullPost.\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.57.\n",
            "Update eps=0.08775210229989679 | kl=0.23874002695083618 | std=0.04393312996362147 | delta=0.08206700208164401 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.5866666666666667.\n",
            "Update eps=0.08687458127689782 | kl=0.26090601086616516 | std=0.04349814847883314 | delta=0.08121208222913663 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6333333333333333.\n",
            "Update eps=0.08600583546412884 | kl=0.26547515392303467 | std=0.04306747374141895 | delta=0.08036643092548956 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.56.\n",
            "Update eps=0.08514577710948755 | kl=0.23360101878643036 | std=0.04264106311031579 | delta=0.07952993997867339 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6433333333333333.\n",
            "Update eps=0.08429431933839267 | kl=0.21669046580791473 | std=0.0422188743666493 | delta=0.07870250262546061 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.56.\n",
            "Update eps=0.08345137614500873 | kl=0.23088745772838593 | std=0.04180086570955376 | delta=0.07788401350897271 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.62.\n",
            "Update eps=0.08261686238355864 | kl=0.17621742188930511 | std=0.041386995752033424 | delta=0.0770743686566576 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.5766666666666667.\n",
            "Update eps=0.08179069375972306 | kl=0.22696350514888763 | std=0.04097722351686477 | delta=0.07627346545868645 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6533333333333333.\n",
            "Update eps=0.08097278682212583 | kl=0.18642641603946686 | std=0.04057150843253938 | delta=0.07548120264676145 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.5733333333333334.\n",
            "Update eps=0.08016305895390458 | kl=0.24604181945323944 | std=0.04016981032924691 | delta=0.07469748027332401 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.65.\n",
            "Update eps=0.07936142836436554 | kl=0.23994913697242737 | std=0.03977208943489793 | delta=0.07392219969115518 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.5633333333333334.\n",
            "Update eps=0.07856781408072187 | kl=0.2691383957862854 | std=0.03937830637118606 | delta=0.07315526353335888 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6033333333333334.\n",
            "Update eps=0.07778213593991465 | kl=0.20334452390670776 | std=0.03898842214968917 | delta=0.07239657569371935 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6433333333333333.\n",
            "Update eps=0.0770043145805155 | kl=0.19425122439861298 | std=0.03860239816800908 | delta=0.07164604130742483 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6066666666666667.\n",
            "Update eps=0.07623427143471034 | kl=0.22220852971076965 | std=0.03822019620594959 | delta=0.07090356673214851 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.5766666666666667.\n",
            "Update eps=0.07547192872036323 | kl=0.2038581669330597 | std=0.03784177842173227 | delta=0.07016905952947956 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6533333333333333.\n",
            "Update eps=0.0747172094331596 | kl=0.17591680586338043 | std=0.03746710734824977 | delta=0.06944242844669596 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6133333333333333.\n",
            "Update eps=0.073970037338828 | kl=0.18930433690547943 | std=0.037096145889356204 | delta=0.06872358339887168 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6233333333333333.\n",
            "Update eps=0.07323033696543972 | kl=0.2258400022983551 | std=0.03672885731619426 | delta=0.06801243545131094 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6466666666666666.\n",
            "Update eps=0.07249803359578533 | kl=0.17324116826057434 | std=0.03636520526355867 | delta=0.06730889680230237 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.61.\n",
            "Update eps=0.07177305325982747 | kl=0.18345041573047638 | std=0.036005153726295716 | delta=0.06661288076618568 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6733333333333333.\n",
            "Update eps=0.0710553227272292 | kl=0.17427827417850494 | std=0.03564866705573833 | delta=0.06592430175672476 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.71.\n",
            "Update eps=0.07034476949995691 | kl=0.17207376658916473 | std=0.03529570995617657 | delta=0.06524307527077977 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6266666666666667.\n",
            "Update eps=0.06964132180495734 | kl=0.15834163129329681 | std=0.03494624748136294 | delta=0.06456911787227229 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6733333333333333.\n",
            "Update eps=0.06894490858690777 | kl=0.14745794236660004 | std=0.03460024503105242 | delta=0.06390234717643707 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6666666666666666.\n",
            "Update eps=0.06825545950103869 | kl=0.17222879827022552 | std=0.03425766834757665 | delta=0.06324268183435398 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6.\n",
            "Update eps=0.0675729049060283 | kl=0.20489436388015747 | std=0.03391848351245213 | delta=0.06259004151775463 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6633333333333333.\n",
            "Update eps=0.06689717585696801 | kl=0.16817660629749298 | std=0.033582656943021906 | delta=0.06194434690409733 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.5733333333333334.\n",
            "Update eps=0.06622820409839833 | kl=0.1925879865884781 | std=0.0332501553891306 | delta=0.06130551966190505 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6666666666666666.\n",
            "Update eps=0.06556592205741435 | kl=0.13091576099395752 | std=0.032920945929832274 | delta=0.06067348243636059 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7466666666666667.\n",
            "Update eps=0.0649102628368402 | kl=0.13273991644382477 | std=0.03259499597013096 | delta=0.06004815883515364 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6833333333333333.\n",
            "Update eps=0.06426116020847181 | kl=0.16542795300483704 | std=0.03227227323775343 | delta=0.05942947341457448 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6733333333333333.\n",
            "Update eps=0.06361854860638709 | kl=0.135945662856102 | std=0.03195274577995389 | delta=0.058817351665848984 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6633333333333333.\n",
            "Update eps=0.06298236312032322 | kl=0.11232289671897888 | std=0.03163638196035039 | delta=0.05821172000171012 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6966666666666667.\n",
            "Update eps=0.06235253948911999 | kl=0.1580900102853775 | std=0.03132315045579246 | delta=0.057612505743200836 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6533333333333333.\n",
            "Update eps=0.06172901409422879 | kl=0.18195658922195435 | std=0.03101302025325986 | delta=0.05701963710670374 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.65.\n",
            "Update eps=0.061111723953286505 | kl=0.14143560826778412 | std=0.03070596064679194 | delta=0.05643304319119265 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.68.\n",
            "Update eps=0.06050060671375364 | kl=0.1253288835287094 | std=0.030401941234447467 | delta=0.05585265396570173 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7233333333333334.\n",
            "Update eps=0.0598956006466161 | kl=0.11956334114074707 | std=0.03010093191529452 | delta=0.05527840025700752 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6933333333333334.\n",
            "Update eps=0.05929664464014994 | kl=0.09913283586502075 | std=0.02980290288643022 | delta=0.05471021373751968 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6966666666666667.\n",
            "Update eps=0.05870367819374844 | kl=0.13446421921253204 | std=0.02950782464002992 | delta=0.0541480269133761 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6733333333333333.\n",
            "Update eps=0.05811664141181096 | kl=0.10900551080703735 | std=0.029215667960425663 | delta=0.05359177311273835 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7266666666666667.\n",
            "Update eps=0.05753547499769285 | kl=0.10613938421010971 | std=0.02892640392121353 | delta=0.05304138647428324 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.66.\n",
            "Update eps=0.05696012024771592 | kl=0.12127593904733658 | std=0.02864000388238963 | delta=0.05249680193588681 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7533333333333333.\n",
            "Update eps=0.05639051904523876 | kl=0.08969377726316452 | std=0.028356439487514484 | delta=0.05195795522349662 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6966666666666667.\n",
            "Update eps=0.05582661385478637 | kl=0.08892824500799179 | std=0.02807568266090543 | delta=0.05142478284018878 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7066666666666667.\n",
            "Update eps=0.05526834771623851 | kl=0.10233122855424881 | std=0.02779770560485686 | delta=0.05089722205540598 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7333333333333333.\n",
            "Update eps=0.054715664239076124 | kl=0.08849245309829712 | std=0.02752248079688798 | delta=0.05037521089437286 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6933333333333334.\n",
            "Update eps=0.054168507596685365 | kl=0.11368346959352493 | std=0.027249980987017804 | delta=0.04985868812768533 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.66.\n",
            "Update eps=0.053626822520718515 | kl=0.12558865547180176 | std=0.026980179195067133 | delta=0.04934759326107041 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.67.\n",
            "Update eps=0.05309055429551133 | kl=0.1124715581536293 | std=0.02671304870798726 | delta=0.048841866525313055 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6866666666666666.\n",
            "Update eps=0.05255964875255621 | kl=0.11490684747695923 | std=0.026448563077215107 | delta=0.04834144886634701 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7366666666666667.\n",
            "Update eps=0.05203405226503065 | kl=0.09742433577775955 | std=0.02618669611605456 | delta=0.04784628193550624 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7266666666666667.\n",
            "Update eps=0.05151371174238034 | kl=0.11185550689697266 | std=0.025927421897083722 | delta=0.04735630807993394 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7266666666666667.\n",
            "Update eps=0.050998574624956536 | kl=0.08624071627855301 | std=0.025670714749587844 | delta=0.046871470333146044 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7666666666666667.\n",
            "Update eps=0.05048858887870697 | kl=0.07688174396753311 | std=0.025416549257017668 | delta=0.04639171240574626 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7366666666666667.\n",
            "Update eps=0.0499837029899199 | kl=0.08428556472063065 | std=0.02516490025447294 | delta=0.04591697867628968 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.73.\n",
            "Update eps=0.049483865960020704 | kl=0.0824965387582779 | std=0.02491574282621083 | delta=0.04544721418229228 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7266666666666667.\n",
            "Update eps=0.0489890273004205 | kl=0.07821419835090637 | std=0.024669052303179038 | delta=0.044982364611383226 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.75.\n",
            "Update eps=0.048499137027416296 | kl=0.10342437773942947 | std=0.024424804260573304 | delta=0.0445223762925976 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.69.\n",
            "Update eps=0.048014145657142134 | kl=0.07671871036291122 | std=0.024182974515419113 | delta=0.04406719618780664 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7533333333333333.\n",
            "Update eps=0.04753400420057071 | kl=0.07439276576042175 | std=0.02394353912417734 | delta=0.04361677188328301 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.79.\n",
            "Update eps=0.047058664158565 | kl=0.07613933831453323 | std=0.023706474380373602 | delta=0.043171051581398605 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7866666666666666.\n",
            "Update eps=0.046588077516979354 | kl=0.06989414989948273 | std=0.023471756812251093 | delta=0.04272998409245216 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7633333333333333.\n",
            "Update eps=0.04612219674180956 | kl=0.07613787800073624 | std=0.023239363180446625 | delta=0.04229351882662467 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7433333333333333.\n",
            "Update eps=0.04566097477439147 | kl=0.0691695436835289 | std=0.02300927047568973 | delta=0.04186160578605967 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.76.\n",
            "Update eps=0.045204365026647556 | kl=0.06290490180253983 | std=0.022781455916524484 | delta=0.04143419555706667 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7566666666666667.\n",
            "Update eps=0.04475232137638108 | kl=0.06878229230642319 | std=0.022555896947053945 | delta=0.0410112393024449 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7566666666666667.\n",
            "Update eps=0.044304798162617266 | kl=0.0704176053404808 | std=0.022332571234706874 | delta=0.0405926887539256 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.78.\n",
            "Update eps=0.043861750180991095 | kl=0.07053432613611221 | std=0.022111456668026608 | delta=0.04017849620473035 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7633333333333333.\n",
            "Update eps=0.04342313267918119 | kl=0.07474423199892044 | std=0.02189253135448179 | delta=0.03976861450224352 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7566666666666667.\n",
            "Update eps=0.04298890135238938 | kl=0.05581839382648468 | std=0.021675773618298803 | delta=0.039362997040796606 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.72.\n",
            "Update eps=0.042559012338865485 | kl=0.06225302442908287 | std=0.02146116199831565 | delta=0.03896159775456257 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.6933333333333334.\n",
            "Update eps=0.04213342221547683 | kl=0.07629810273647308 | std=0.021248675245857076 | delta=0.038564371110558014 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.76.\n",
            "Update eps=0.04171208799332206 | kl=0.06230983883142471 | std=0.02103829232263077 | delta=0.03817127210175139 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.74.\n",
            "Update eps=0.041294967113388835 | kl=0.06505609303712845 | std=0.020829992398644324 | delta=0.03778225624027526 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7833333333333333.\n",
            "Update eps=0.04088201744225495 | kl=0.05884334072470665 | std=0.020623754850142895 | delta=0.037397279550740674 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7866666666666666.\n",
            "Update eps=0.0404731972678324 | kl=0.054445959627628326 | std=0.02041955925756722 | delta=0.037016298563652024 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.83.\n",
            "Update eps=0.04006846529515407 | kl=0.051732078194618225 | std=0.020217385403531903 | delta=0.03663927030892038 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.8.\n",
            "Update eps=0.039667780642202534 | kl=0.05210410803556442 | std=0.020017213270823668 | delta=0.03626615230947362 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.78.\n",
            "Update eps=0.03927110283578051 | kl=0.056239496916532516 | std=0.01981902304041947 | delta=0.03589690257496177 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.77.\n",
            "Update eps=0.0388783918074227 | kl=0.058666057884693146 | std=0.01962279508952423 | delta=0.035531479595555596 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.78.\n",
            "Update eps=0.03848960788934848 | kl=0.06345851719379425 | std=0.01942850998962795 | delta=0.03516984233583708 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7933333333333333.\n",
            "Update eps=0.038104711810454994 | kl=0.03997479006648064 | std=0.019236148504582128 | delta=0.03481195022878002 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.8366666666666667.\n",
            "Update eps=0.037723664692350445 | kl=0.045478593558073044 | std=0.019045691588695176 | delta=0.03445776316981913 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7433333333333333.\n",
            "Update eps=0.03734642804542694 | kl=0.05661746859550476 | std=0.018857120384846708 | delta=0.0341072415110063 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7866666666666666.\n",
            "Update eps=0.03697296376497267 | kl=0.05877126008272171 | std=0.018670416222620504 | delta=0.03376034605525223 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "Training RMS-bnn for 100 steps...\n",
            "Training Dropout-bnn for 100 steps...\n",
            "Training BBB-bnn for 100 steps...\n",
            "Training NeuralLinear-bnn for 100 steps...\n",
            "Training NeuralLinear2-bnn for 100 steps...\n",
            "Training BootRMS-0-bnn for 100 steps...\n",
            "Training BootRMS-1-bnn for 100 steps...\n",
            "Training BootRMS-2-bnn for 100 steps...\n",
            "Training ParamNoise-bnn for 100 steps...\n",
            "ParamNoise | % of agreement btw original / corrupted actions: 0.7733333333333333.\n",
            "Update eps=0.03660323412732295 | kl=0.05792298540472984 | std=0.018485560616455943 | delta=0.03341703805065216 | increase=False.\n",
            "Training BBAlphaDiv-bnn for 100 steps...\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "census bandit completed after 4714.072419166565 seconds.\n",
            "---------------------------------------------------\n",
            "  0) Dropout             | \t \t total reward =     2699.0.\n",
            "  1) BBB                 | \t \t total reward =     2177.0.\n",
            "  2) NeuralLinear        | \t \t total reward =     1980.0.\n",
            "  3) NeuralLinear2       | \t \t total reward =     1855.0.\n",
            "  4) BootRMS             | \t \t total reward =     1844.0.\n",
            "  5) LinFullPost         | \t \t total reward =     1777.0.\n",
            "  6) ParamNoise          | \t \t total reward =     1543.0.\n",
            "  7) RMS                 | \t \t total reward =     1395.0.\n",
            "  8) Uniform Sampling    | \t \t total reward =      576.0.\n",
            "  9) BBAlphaDiv          | \t \t total reward =      514.0.\n",
            "---------------------------------------------------\n",
            "Optimal total reward = 5000.0.\n",
            "Frequency of optimal actions (action, frequency):\n",
            "[[0, 2010], [1, 697], [2, 906], [3, 439], [4, 101], [5, 324], [6, 503], [7, 9], [8, 11]]\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCuUlhKCEUpe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}